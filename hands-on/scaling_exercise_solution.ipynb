{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On: Strong and Weak Scaling with SLURM\n",
    "\n",
    "**Objective:** Apply Amdahl's and Gustafson's Laws in practice by measuring strong and weak scaling on an HPC cluster.\n",
    "\n",
    "In this exercise, you will:\n",
    "1. Compile an OpenMP-parallelized Julia set computation\n",
    "2. Submit SLURM job arrays to measure strong and weak scaling\n",
    "3. Analyze the results and compare them to theoretical predictions\n",
    "\n",
    "---\n",
    "\n",
    "**Acknowledgment:** This exercise is based on the excellent tutorial [\"Scalability: Strong and Weak Scaling\"](https://www.kth.se/blogs/pdc/2018/11/scalability-strong-and-weak-scaling/) from KTH PDC, and uses the Julia set OpenMP code originally from [John Burkardt (FSU)](https://people.sc.fsu.edu/~jburkardt/c_src/julia_set_openmp/julia_set_openmp.c).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theory Recap\n",
    "\n",
    "### Strong Scaling (Amdahl's Law)\n",
    "\n",
    "**Question:** How much faster can we solve a *fixed-size* problem by adding more processors?\n",
    "\n",
    "$$S(N) = \\frac{1}{(1-p) + \\frac{p}{N}}$$\n",
    "\n",
    "Where:\n",
    "- $S(N)$ = speedup with $N$ processors\n",
    "- $p$ = parallelizable fraction of the code\n",
    "- $(1-p)$ = serial fraction\n",
    "\n",
    "**Key insight:** Even with infinite processors, speedup is limited by the serial fraction: $S_{max} = \\frac{1}{1-p}$\n",
    "\n",
    "### Weak Scaling (Gustafson's Law)\n",
    "\n",
    "**Question:** How much larger a problem can we solve in the *same time* by adding more processors?\n",
    "\n",
    "$$S(N) = N - s(N-1) = s + p \\cdot N$$\n",
    "\n",
    "Where:\n",
    "- $s$ = serial fraction\n",
    "- $p = 1 - s$ = parallel fraction\n",
    "\n",
    "**Key insight:** Speedup grows linearly with $N$ — more optimistic for large-scale computing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Julia Set Algorithm\n",
    "\n",
    "The [Julia set](https://en.wikipedia.org/wiki/Julia_set) is a fractal defined by iterating the complex function:\n",
    "\n",
    "$$Z_{k+1} = Z_k^2 + C$$\n",
    "\n",
    "For each pixel (mapped to a complex number $Z_0$), we iterate until either:\n",
    "- The magnitude $|Z_k|$ exceeds a threshold (point escapes → not in set)\n",
    "- We reach the maximum iterations (point stays bounded → in set)\n",
    "\n",
    "The iteration count determines the pixel color, producing beautiful fractal images.\n",
    "\n",
    "**Why Julia set for scaling tests?**\n",
    "- Each pixel is computed independently → embarrassingly parallel\n",
    "- Computation time scales linearly with image size\n",
    "- Easy to vary problem size (just change resolution)\n",
    "\n",
    "We use $C = -0.8 + 0.156i$ which produces a visually interesting fractal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup\n",
    "\n",
    "First, let's create the necessary directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create directories for logs and output\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "print(\"Directories created:\")\n",
    "print(\"  - logs/   (SLURM output files)\")\n",
    "print(\"  - output/ (Julia set images)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The C Code\n",
    "\n",
    "The following cell writes the OpenMP-parallelized Julia set code to `julia_set.c`.\n",
    "\n",
    "Key features:\n",
    "- Uses `#pragma omp parallel for` to distribute pixel computation across threads\n",
    "- Uses `omp_get_wtime()` for precise timing\n",
    "- Outputs timing info to stdout (captured by SLURM)\n",
    "- Writes image as binary file (easy to read in Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile julia_set.c\n",
    "/*\n",
    " * Julia Set computation with OpenMP parallelization\n",
    " * \n",
    " * Based on code from John Burkardt (FSU) and the KTH PDC tutorial:\n",
    " * https://www.kth.se/blogs/pdc/2018/11/scalability-strong-and-weak-scaling/\n",
    " * https://people.sc.fsu.edu/~jburkardt/c_src/julia_set_openmp/julia_set_openmp.c\n",
    " *\n",
    " * Usage: ./julia_set <width> <height> <output_file>\n",
    " * Thread count is controlled via OMP_NUM_THREADS environment variable.\n",
    " */\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <stdint.h>\n",
    "#include <omp.h>\n",
    "\n",
    "/* Julia set parameters */\n",
    "#define C_REAL -0.8\n",
    "#define C_IMAG  0.156\n",
    "#define MAX_ITER 200\n",
    "#define ESCAPE_RADIUS 1000.0\n",
    "\n",
    "/* Domain boundaries */\n",
    "#define X_MIN -1.5\n",
    "#define X_MAX  1.5\n",
    "#define Y_MIN -1.5\n",
    "#define Y_MAX  1.5\n",
    "\n",
    "/*\n",
    " * Compute the iteration count for a single point.\n",
    " * Returns the number of iterations before escape, or MAX_ITER if bounded.\n",
    " */\n",
    "int julia_iterate(double x0, double y0) {\n",
    "    double x = x0;\n",
    "    double y = y0;\n",
    "    int iter;\n",
    "    \n",
    "    for (iter = 0; iter < MAX_ITER; iter++) {\n",
    "        double x_new = x * x - y * y + C_REAL;\n",
    "        double y_new = 2.0 * x * y + C_IMAG;\n",
    "        x = x_new;\n",
    "        y = y_new;\n",
    "        \n",
    "        if (x * x + y * y > ESCAPE_RADIUS * ESCAPE_RADIUS) {\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return iter;\n",
    "}\n",
    "\n",
    "/*\n",
    " * Compute the Julia set for the entire image.\n",
    " * This is where OpenMP parallelization happens.\n",
    " */\n",
    "void compute_julia_set(unsigned char *image, int width, int height) {\n",
    "    double x_scale = (X_MAX - X_MIN) / (double)(width - 1);\n",
    "    double y_scale = (Y_MAX - Y_MIN) / (double)(height - 1);\n",
    "    \n",
    "    #pragma omp parallel for schedule(dynamic)\n",
    "    for (int j = 0; j < height; j++) {\n",
    "        double y0 = Y_MAX - j * y_scale;  /* Flip y for image coordinates */\n",
    "        \n",
    "        for (int i = 0; i < width; i++) {\n",
    "            double x0 = X_MIN + i * x_scale;\n",
    "            int iter = julia_iterate(x0, y0);\n",
    "            \n",
    "            /* Map iteration count to grayscale (0-255) */\n",
    "            image[j * width + i] = (unsigned char)(iter % 256);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "/*\n",
    " * Write the image as a binary file.\n",
    " * Format: [width (4 bytes)] [height (4 bytes)] [pixels (width*height bytes)]\n",
    " */\n",
    "int write_binary_image(const char *filename, unsigned char *image, int width, int height) {\n",
    "    FILE *fp = fopen(filename, \"wb\");\n",
    "    if (fp == NULL) {\n",
    "        fprintf(stderr, \"Error: Cannot open file %s for writing\\n\", filename);\n",
    "        return -1;\n",
    "    }\n",
    "    \n",
    "    /* Write header: width and height as 32-bit integers */\n",
    "    int32_t w = width;\n",
    "    int32_t h = height;\n",
    "    fwrite(&w, sizeof(int32_t), 1, fp);\n",
    "    fwrite(&h, sizeof(int32_t), 1, fp);\n",
    "    \n",
    "    /* Write pixel data */\n",
    "    fwrite(image, sizeof(unsigned char), width * height, fp);\n",
    "    \n",
    "    fclose(fp);\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "    if (argc < 4) {\n",
    "        printf(\"Usage: %s <width> <height> <output_file>\\n\", argv[0]);\n",
    "        printf(\"Thread count is controlled via OMP_NUM_THREADS.\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    int width = atoi(argv[1]);\n",
    "    int height = atoi(argv[2]);\n",
    "    const char *output_file = argv[3];\n",
    "    \n",
    "    /* Get thread count */\n",
    "    int num_threads;\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        #pragma omp single\n",
    "        num_threads = omp_get_num_threads();\n",
    "    }\n",
    "    \n",
    "    /* Allocate image buffer */\n",
    "    unsigned char *image = (unsigned char *)malloc(width * height * sizeof(unsigned char));\n",
    "    if (image == NULL) {\n",
    "        fprintf(stderr, \"Error: Cannot allocate memory for %dx%d image\\n\", width, height);\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    /* Compute Julia set with timing */\n",
    "    double start_time = omp_get_wtime();\n",
    "    compute_julia_set(image, width, height);\n",
    "    double end_time = omp_get_wtime();\n",
    "    double elapsed = end_time - start_time;\n",
    "    \n",
    "    /* Output timing information (parsed by Python later) */\n",
    "    printf(\"Threads: %d\\n\", num_threads);\n",
    "    printf(\"Width: %d\\n\", width);\n",
    "    printf(\"Height: %d\\n\", height);\n",
    "    printf(\"Time: %.6f\\n\", elapsed);\n",
    "    \n",
    "    /* Write output image */\n",
    "    if (write_binary_image(output_file, image, width, height) != 0) {\n",
    "        free(image);\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    printf(\"Output: %s\\n\", output_file);\n",
    "    \n",
    "    free(image);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compilation\n",
    "\n",
    "Compile the code with OpenMP support. Run this command in your terminal:\n",
    "\n",
    "```bash\n",
    "gcc -O3 -fopenmp -o julia_set julia_set.c -lm\n",
    "```\n",
    "\n",
    "Flags:\n",
    "- `-O3`: Aggressive optimization\n",
    "- `-fopenmp`: Enable OpenMP support\n",
    "- `-lm`: Link math library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also compile from within the notebook:\n",
    "!gcc -O3 -fopenmp -o julia_set julia_set.c -lm && echo \"Compilation successful!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Local Test (Optional)\n",
    "\n",
    "Before submitting to SLURM, let's verify the code works locally with a small test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick local test with 2 threads and small image\n",
    "!OMP_NUM_THREADS=2 ./julia_set 500 500 output/test_local.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the test output\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_julia_image(filename):\n",
    "    \"\"\"Read a binary Julia set image file.\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Read header\n",
    "        width = np.frombuffer(f.read(4), dtype=np.int32)[0]\n",
    "        height = np.frombuffer(f.read(4), dtype=np.int32)[0]\n",
    "        # Read pixel data\n",
    "        pixels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return pixels.reshape(height, width)\n",
    "\n",
    "# Display the test image\n",
    "img = read_julia_image('output/test_local.bin')\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img, cmap='hot')\n",
    "plt.colorbar(label='Iterations')\n",
    "plt.title('Julia Set (local test)')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Strong Scaling Experiment\n",
    "\n",
    "**Goal:** Measure how execution time decreases as we add more cores to a *fixed-size* problem.\n",
    "\n",
    "**Setup:**\n",
    "- Fixed problem size: **4000 × 4000** pixels\n",
    "- Vary thread count: 1, 2, 4, 8, 16, 24, 32, 48\n",
    "- Reserve full node (`--cpus-per-task 48`) to avoid interference from other jobs\n",
    "\n",
    "**Expected behavior:** Speedup will increase with cores but eventually plateau (Amdahl's Law)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile job_strong_scaling.sh\n",
    "#!/bin/bash -l\n",
    "\n",
    "# =============================================================================\n",
    "# Strong Scaling Experiment - Julia Set\n",
    "# Fixed problem size (4000x4000), varying thread count\n",
    "# =============================================================================\n",
    "\n",
    "# Job general details\n",
    "#SBATCH --job-name JuliaSet_StrongScaling\n",
    "#SBATCH --account rfabbret_cours_hpc\n",
    "#SBATCH --mail-type NONE\n",
    "#SBATCH --time 00:29:59\n",
    "\n",
    "# Paths and output\n",
    "#SBATCH --output logs/strong_scaling_%A_%a.out\n",
    "\n",
    "# Resources - reserve full node to avoid interference\n",
    "#SBATCH --nodes 1\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --cpus-per-task 48\n",
    "#SBATCH --mem 8G\n",
    "\n",
    "# Node specificities\n",
    "#SBATCH --partition cpu\n",
    "\n",
    "# Array: each task ID is the number of threads to use\n",
    "#SBATCH --array 1,2,4,8,16,24,32,48\n",
    "\n",
    "# Clean environment\n",
    "#SBATCH --export NONE\n",
    "\n",
    "# =============================================================================\n",
    "# Job execution\n",
    "# =============================================================================\n",
    "\n",
    "# Set thread count from array task ID\n",
    "export OMP_NUM_THREADS=${SLURM_ARRAY_TASK_ID}\n",
    "\n",
    "# Fixed problem size for strong scaling\n",
    "WIDTH=4000\n",
    "HEIGHT=4000\n",
    "\n",
    "# Output file\n",
    "OUTPUT_FILE=\"output/strong_${SLURM_ARRAY_TASK_ID}cores.bin\"\n",
    "\n",
    "echo \"=== Strong Scaling Experiment ===\"\n",
    "echo \"Job ID: ${SLURM_JOB_ID}\"\n",
    "echo \"Array Task ID: ${SLURM_ARRAY_TASK_ID}\"\n",
    "echo \"Threads: ${OMP_NUM_THREADS}\"\n",
    "echo \"Problem size: ${WIDTH} x ${HEIGHT}\"\n",
    "echo \"\"\n",
    "\n",
    "# Run the Julia set computation\n",
    "./julia_set ${WIDTH} ${HEIGHT} ${OUTPUT_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the Strong Scaling Job\n",
    "\n",
    "Run this command in your terminal:\n",
    "\n",
    "```bash\n",
    "sbatch job_strong_scaling.sh\n",
    "```\n",
    "\n",
    "Monitor your jobs with:\n",
    "```bash\n",
    "squeue -u $USER\n",
    "```\n",
    "\n",
    "Wait for all array tasks to complete before proceeding to the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Weak Scaling Experiment\n",
    "\n",
    "**Goal:** Measure how execution time stays constant as we scale *both* problem size and cores proportionally.\n",
    "\n",
    "**Setup:**\n",
    "- Base problem size: **1000 × 1000** pixels for 1 core\n",
    "- Scale both dimensions by $\\sqrt{N}$ where $N$ is the thread count\n",
    "- This keeps work per thread constant (each thread processes ~1M pixels)\n",
    "\n",
    "| Threads | Width | Height | Total Pixels | Pixels/Thread |\n",
    "|---------|-------|--------|--------------|---------------|\n",
    "| 1 | 1000 | 1000 | 1M | 1M |\n",
    "| 4 | 2000 | 2000 | 4M | 1M |\n",
    "| 16 | 4000 | 4000 | 16M | 1M |\n",
    "| 48 | 6928 | 6928 | ~48M | 1M |\n",
    "\n",
    "**Expected behavior:** Execution time should remain roughly constant (Gustafson's Law)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile job_weak_scaling.sh\n",
    "#!/bin/bash -l\n",
    "\n",
    "# =============================================================================\n",
    "# Weak Scaling Experiment - Julia Set\n",
    "# Problem size scales with thread count (constant work per thread)\n",
    "# =============================================================================\n",
    "\n",
    "# Job general details\n",
    "#SBATCH --job-name JuliaSet_WeakScaling\n",
    "#SBATCH --account rfabbret_cours_hpc\n",
    "#SBATCH --mail-type NONE\n",
    "#SBATCH --time 00:29:59\n",
    "\n",
    "# Paths and output\n",
    "#SBATCH --output logs/weak_scaling_%A_%a.out\n",
    "\n",
    "# Resources - reserve full node to avoid interference\n",
    "#SBATCH --nodes 1\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --cpus-per-task 48\n",
    "#SBATCH --mem 8G\n",
    "\n",
    "# Node specificities\n",
    "#SBATCH --partition cpu\n",
    "\n",
    "# Array: each task ID is the number of threads to use\n",
    "#SBATCH --array 1,2,4,8,16,24,32,48\n",
    "\n",
    "# Clean environment\n",
    "#SBATCH --export NONE\n",
    "\n",
    "# =============================================================================\n",
    "# Job execution\n",
    "# =============================================================================\n",
    "\n",
    "# Set thread count from array task ID\n",
    "export OMP_NUM_THREADS=${SLURM_ARRAY_TASK_ID}\n",
    "\n",
    "# Base size for 1 thread\n",
    "BASE_SIZE=1000\n",
    "\n",
    "# Scale dimensions by sqrt(N) to keep work per thread constant\n",
    "# Using bc for floating point math, then converting to integer\n",
    "SCALE=$(echo \"scale=6; sqrt(${SLURM_ARRAY_TASK_ID})\" | bc)\n",
    "WIDTH=$(echo \"${BASE_SIZE} * ${SCALE}\" | bc | cut -d'.' -f1)\n",
    "HEIGHT=${WIDTH}  # Keep square\n",
    "\n",
    "# Output file\n",
    "OUTPUT_FILE=\"output/weak_${SLURM_ARRAY_TASK_ID}cores.bin\"\n",
    "\n",
    "echo \"=== Weak Scaling Experiment ===\"\n",
    "echo \"Job ID: ${SLURM_JOB_ID}\"\n",
    "echo \"Array Task ID: ${SLURM_ARRAY_TASK_ID}\"\n",
    "echo \"Threads: ${OMP_NUM_THREADS}\"\n",
    "echo \"Scale factor: ${SCALE}\"\n",
    "echo \"Problem size: ${WIDTH} x ${HEIGHT}\"\n",
    "echo \"\"\n",
    "\n",
    "# Run the Julia set computation\n",
    "./julia_set ${WIDTH} ${HEIGHT} ${OUTPUT_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the Weak Scaling Job\n",
    "\n",
    "Run this command in your terminal:\n",
    "\n",
    "```bash\n",
    "sbatch job_weak_scaling.sh\n",
    "```\n",
    "\n",
    "Monitor your jobs with:\n",
    "```bash\n",
    "squeue -u $USER\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Results Analysis\n",
    "\n",
    "Once all jobs have completed, run the following cells to parse the output files and generate plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def parse_slurm_output(filename):\n",
    "    \"\"\"Parse a SLURM output file to extract timing information.\"\"\"\n",
    "    result = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "        # Extract key-value pairs\n",
    "        for line in content.split('\\n'):\n",
    "            if ':' in line:\n",
    "                parts = line.split(':', 1)\n",
    "                if len(parts) == 2:\n",
    "                    key = parts[0].strip()\n",
    "                    value = parts[1].strip()\n",
    "                    \n",
    "                    # Try to convert to number\n",
    "                    try:\n",
    "                        if '.' in value:\n",
    "                            result[key] = float(value)\n",
    "                        else:\n",
    "                            result[key] = int(value)\n",
    "                    except ValueError:\n",
    "                        result[key] = value\n",
    "    \n",
    "    return result\n",
    "\n",
    "def collect_results(pattern):\n",
    "    \"\"\"Collect results from all matching SLURM output files.\"\"\"\n",
    "    files = glob.glob(pattern)\n",
    "    results = []\n",
    "    \n",
    "    for f in files:\n",
    "        data = parse_slurm_output(f)\n",
    "        if 'Threads' in data and 'Time' in data:\n",
    "            results.append(data)\n",
    "    \n",
    "    # Sort by thread count\n",
    "    results.sort(key=lambda x: x['Threads'])\n",
    "    return results\n",
    "\n",
    "print(\"Analysis functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect strong scaling results\n",
    "strong_results = collect_results('logs/strong_scaling_*.out')\n",
    "\n",
    "print(\"Strong Scaling Results:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Threads':>10} {'Time (s)':>12} {'Speedup':>10} {'Efficiency':>12}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if strong_results:\n",
    "    t1 = strong_results[0]['Time']  # Baseline (1 thread)\n",
    "    \n",
    "    for r in strong_results:\n",
    "        threads = r['Threads']\n",
    "        time = r['Time']\n",
    "        speedup = t1 / time\n",
    "        efficiency = speedup / threads * 100\n",
    "        print(f\"{threads:>10} {time:>12.4f} {speedup:>10.2f} {efficiency:>11.1f}%\")\n",
    "else:\n",
    "    print(\"No results found. Have the jobs completed?\")\n",
    "    print(\"Check with: squeue -u $USER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect weak scaling results\n",
    "weak_results = collect_results('logs/weak_scaling_*.out')\n",
    "\n",
    "print(\"Weak Scaling Results:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Threads':>10} {'Size':>12} {'Time (s)':>12} {'Scaled Speedup':>15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if weak_results:\n",
    "    t1 = weak_results[0]['Time']  # Baseline (1 thread)\n",
    "    \n",
    "    for r in weak_results:\n",
    "        threads = r['Threads']\n",
    "        width = r.get('Width', '?')\n",
    "        height = r.get('Height', '?')\n",
    "        time = r['Time']\n",
    "        # For weak scaling, \"scaled speedup\" = N * T1 / TN\n",
    "        # (how much more work we did in the same time)\n",
    "        scaled_speedup = threads * t1 / time\n",
    "        print(f\"{threads:>10} {width}x{height:>6} {time:>12.4f} {scaled_speedup:>15.2f}\")\n",
    "else:\n",
    "    print(\"No results found. Have the jobs completed?\")\n",
    "    print(\"Check with: squeue -u $USER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Scaling Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strong_scaling(results):\n",
    "    \"\"\"Plot strong scaling results with Amdahl's Law comparison.\"\"\"\n",
    "    if not results:\n",
    "        print(\"No strong scaling results to plot.\")\n",
    "        return\n",
    "    \n",
    "    threads = np.array([r['Threads'] for r in results])\n",
    "    times = np.array([r['Time'] for r in results])\n",
    "    t1 = times[0]\n",
    "    speedup = t1 / times\n",
    "    efficiency = speedup / threads\n",
    "    \n",
    "    # Estimate parallel fraction from data\n",
    "    # Using Amdahl's formula: S = 1 / ((1-p) + p/N)\n",
    "    # Rearranging: p = (1 - 1/S) / (1 - 1/N)\n",
    "    # Use the last data point for estimation\n",
    "    S_max = speedup[-1]\n",
    "    N_max = threads[-1]\n",
    "    p_estimated = (1 - 1/S_max) / (1 - 1/N_max) if N_max > 1 else 0.95\n",
    "    p_estimated = min(0.999, max(0.5, p_estimated))  # Clamp to reasonable range\n",
    "    \n",
    "    # Theoretical curves\n",
    "    n_theory = np.linspace(1, max(threads), 100)\n",
    "    ideal = n_theory\n",
    "    amdahl = 1 / ((1 - p_estimated) + p_estimated / n_theory)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Speedup plot\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(n_theory, ideal, 'k--', label='Ideal (linear)', linewidth=1.5)\n",
    "    ax1.plot(n_theory, amdahl, 'b-', label=f\"Amdahl's Law (p={p_estimated:.3f})\", linewidth=1.5)\n",
    "    ax1.plot(threads, speedup, 'ro-', label='Measured', markersize=8, linewidth=2)\n",
    "    ax1.set_xlabel('Number of Threads', fontsize=12)\n",
    "    ax1.set_ylabel('Speedup', fontsize=12)\n",
    "    ax1.set_title('Strong Scaling: Speedup', fontsize=14)\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(0, max(threads) + 2)\n",
    "    ax1.set_ylim(0, max(speedup) * 1.2)\n",
    "    \n",
    "    # Efficiency plot\n",
    "    ax2 = axes[1]\n",
    "    ax2.axhline(y=1.0, color='k', linestyle='--', label='Ideal (100%)', linewidth=1.5)\n",
    "    ax2.plot(n_theory, amdahl / n_theory, 'b-', label=f\"Amdahl's Law (p={p_estimated:.3f})\", linewidth=1.5)\n",
    "    ax2.plot(threads, efficiency, 'ro-', label='Measured', markersize=8, linewidth=2)\n",
    "    ax2.set_xlabel('Number of Threads', fontsize=12)\n",
    "    ax2.set_ylabel('Efficiency (Speedup / Threads)', fontsize=12)\n",
    "    ax2.set_title('Strong Scaling: Efficiency', fontsize=14)\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xlim(0, max(threads) + 2)\n",
    "    ax2.set_ylim(0, 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output/strong_scaling_plot.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nEstimated parallel fraction: p = {p_estimated:.4f}\")\n",
    "    print(f\"Theoretical max speedup (Amdahl): {1/(1-p_estimated):.2f}x\")\n",
    "\n",
    "plot_strong_scaling(strong_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weak_scaling(results):\n",
    "    \"\"\"Plot weak scaling results.\"\"\"\n",
    "    if not results:\n",
    "        print(\"No weak scaling results to plot.\")\n",
    "        return\n",
    "    \n",
    "    threads = np.array([r['Threads'] for r in results])\n",
    "    times = np.array([r['Time'] for r in results])\n",
    "    t1 = times[0]\n",
    "    \n",
    "    # For weak scaling, we want time to stay constant (ideal)\n",
    "    # Scaled speedup = N * T1 / TN (how much more work in same time)\n",
    "    scaled_speedup = threads * t1 / times\n",
    "    \n",
    "    # Normalized time (relative to single-thread time)\n",
    "    normalized_time = times / t1\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Execution time plot\n",
    "    ax1 = axes[0]\n",
    "    ax1.axhline(y=t1, color='k', linestyle='--', label=f'Ideal ({t1:.2f}s)', linewidth=1.5)\n",
    "    ax1.plot(threads, times, 'go-', label='Measured', markersize=8, linewidth=2)\n",
    "    ax1.set_xlabel('Number of Threads', fontsize=12)\n",
    "    ax1.set_ylabel('Execution Time (s)', fontsize=12)\n",
    "    ax1.set_title('Weak Scaling: Execution Time', fontsize=14)\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(0, max(threads) + 2)\n",
    "    \n",
    "    # Scaled speedup plot\n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(threads, threads, 'k--', label='Ideal (linear)', linewidth=1.5)\n",
    "    ax2.plot(threads, scaled_speedup, 'go-', label='Measured', markersize=8, linewidth=2)\n",
    "    ax2.set_xlabel('Number of Threads', fontsize=12)\n",
    "    ax2.set_ylabel('Scaled Speedup (N × T₁ / Tₙ)', fontsize=12)\n",
    "    ax2.set_title('Weak Scaling: Scaled Speedup', fontsize=14)\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xlim(0, max(threads) + 2)\n",
    "    ax2.set_ylim(0, max(threads) * 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output/weak_scaling_plot.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate weak scaling efficiency\n",
    "    weak_efficiency = t1 / times\n",
    "    print(f\"\\nWeak Scaling Efficiency (T1/TN):\")\n",
    "    for i, (n, eff) in enumerate(zip(threads, weak_efficiency)):\n",
    "        print(f\"  {n:2d} threads: {eff*100:.1f}%\")\n",
    "\n",
    "plot_weak_scaling(weak_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Julia Set Visualization\n",
    "\n",
    "Let's visualize one of the computed Julia set images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the largest computed image (48 cores, strong scaling)\n",
    "image_file = 'output/strong_48cores.bin'\n",
    "\n",
    "if os.path.exists(image_file):\n",
    "    img = read_julia_image(image_file)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    im = ax.imshow(img, cmap='hot')\n",
    "    plt.colorbar(im, ax=ax, label='Iterations', shrink=0.8)\n",
    "    ax.set_title(f'Julia Set (C = -0.8 + 0.156i)\\n{img.shape[1]} × {img.shape[0]} pixels', fontsize=14)\n",
    "    ax.axis('off')\n",
    "    plt.savefig('output/julia_set_visualization.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Image file not found: {image_file}\")\n",
    "    print(\"Run the strong scaling experiment first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare images from weak scaling (different sizes)\n",
    "weak_files = sorted(glob.glob('output/weak_*cores.bin'))\n",
    "\n",
    "if len(weak_files) >= 4:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "    \n",
    "    # Select 4 representative images\n",
    "    selected = [weak_files[0], weak_files[2], weak_files[4], weak_files[-1]]\n",
    "    \n",
    "    for ax, f in zip(axes.flat, selected):\n",
    "        if os.path.exists(f):\n",
    "            img = read_julia_image(f)\n",
    "            cores = os.path.basename(f).split('_')[1].replace('cores.bin', '')\n",
    "            ax.imshow(img, cmap='hot')\n",
    "            ax.set_title(f'{cores} cores: {img.shape[1]}×{img.shape[0]}', fontsize=12)\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('Weak Scaling: Problem Size Grows with Cores', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output/weak_scaling_images.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough weak scaling images found.\")\n",
    "    print(\"Run the weak scaling experiment first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Discussion Questions\n",
    "\n",
    "After completing the experiments, consider these questions:\n",
    "\n",
    "1. **Strong Scaling:**\n",
    "   - Does the measured speedup match Amdahl's Law prediction?\n",
    "   - What is the estimated parallel fraction of the code?\n",
    "   - At what thread count does adding more cores become inefficient (efficiency < 50%)?\n",
    "\n",
    "2. **Weak Scaling:**\n",
    "   - Does execution time stay constant as we scale up?\n",
    "   - Why might weak scaling efficiency decrease with more cores?\n",
    "   - Which scaling behavior (strong or weak) is more relevant for your research?\n",
    "\n",
    "3. **Practical Considerations:**\n",
    "   - Why did we reserve the full node even when using fewer cores?\n",
    "   - How would results differ if other jobs were running on the same node?\n",
    "   - What factors besides serial code fraction affect scaling? (hint: memory bandwidth, cache effects)\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You have successfully measured strong and weak scaling on an HPC cluster and connected the results to Amdahl's and Gustafson's Laws."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
